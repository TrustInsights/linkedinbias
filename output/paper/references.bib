% References for: Gender Bias in LLaMA-3 Embeddings
% Bibliography file for ACL-style citations

% ============================================================================
% LinkedIn Technical Papers
% ============================================================================

@article{linkedin2024retrieval,
    title={Large Scale Retrieval for the LinkedIn Feed using Causal Language Models},
    author={Gupta, Ravi and others},
    journal={arXiv preprint arXiv:2510.14223},
    year={2024},
    url={https://arxiv.org/abs/2510.14223}
}

@article{linkedin2024360brew,
    title={360Brew: A Decoder-only Foundation Model for Personalized Ranking and Recommendation},
    author={LinkedIn AI Team},
    journal={arXiv preprint arXiv:2501.16450},
    year={2025},
    url={https://arxiv.org/abs/2501.16450v4}
}

@misc{linkedin2024speculative,
    title={Accelerating LLM inference with speculative decoding: Lessons from LinkedIn's Hiring Assistant},
    author={LinkedIn Engineering},
    year={2024},
    howpublished={LinkedIn Engineering Blog},
    url={https://www.linkedin.com/blog/engineering/ai/accelerating-llm-inference-with-speculative-decoding-lessons-from-linkedins-hiring-assistant}
}

@misc{linkedin2024fishdb,
    title={FishDB: A generic retrieval engine for scaling LinkedIn's feed},
    author={LinkedIn Engineering},
    year={2024},
    howpublished={LinkedIn Engineering Blog},
    url={https://www.linkedin.com/blog/engineering/infrastructure/fishdb-a-generic-retrieval-engine-for-scaling-linkedins-feed}
}

@misc{linkedin2024,
    title={About LinkedIn},
    author={{LinkedIn Corporation}},
    year={2024},
    howpublished={LinkedIn},
    note={Over 1 billion members worldwide}
}

@misc{linkedin2025sglang,
    title={Turbocharging LinkedIn's Recommendation Systems with SGLang},
    author={Shimizu, Steven and Lan, Qing and Dharamsi, Tejas and Ramachandran, Sundara Raman and De, Arup and Wang, Yubo and Gupta, Akhilesh and Chen, Yanning and Fatahi, Ata and Wang, Zhipeng and H., Biao},
    year={2025},
    howpublished={LinkedIn Engineering Blog},
    url={https://www.linkedin.com/blog/engineering/ai/turbocharging-linkedins-recommendation-systems-with-sglang}
}

% ============================================================================
% Embedding Bias Research
% ============================================================================

@article{caliskan2017semantics,
    title={Semantics derived automatically from language corpora contain human-like biases},
    author={Caliskan, Aylin and Bryson, Joanna J and Narayanan, Arvind},
    journal={Science},
    volume={356},
    number={6334},
    pages={183--186},
    year={2017},
    publisher={American Association for the Advancement of Science},
    doi={10.1126/science.aal4230}
}

@inproceedings{may2019measuring,
    title={On Measuring Social Biases in Sentence Encoders},
    author={May, Chandler and Wang, Alex and Borber, Shikha and Bowman, Samuel R and Rudinger, Rachel},
    booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
    pages={622--628},
    year={2019},
    organization={Association for Computational Linguistics}
}

@inproceedings{kurita2019measuring,
    title={Measuring Bias in Contextualized Word Representations},
    author={Kurita, Keita and Vyas, Nidhi and Pareek, Ayush and Black, Alan W and Tsvetkov, Yulia},
    booktitle={Proceedings of the First Workshop on Gender Bias in Natural Language Processing},
    pages={166--172},
    year={2019},
    organization={Association for Computational Linguistics}
}

@article{bolukbasi2016man,
    title={Man is to computer programmer as woman is to homemaker? Debiasing word embeddings},
    author={Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T},
    journal={Advances in Neural Information Processing Systems},
    volume={29},
    year={2016}
}

% ============================================================================
% Name-Based Discrimination Research
% ============================================================================

@article{bertrand2004emily,
    title={Are Emily and Greg more employable than Lakisha and Jamal? A field experiment on labor market discrimination},
    author={Bertrand, Marianne and Mullainathan, Sendhil},
    journal={American Economic Review},
    volume={94},
    number={4},
    pages={991--1013},
    year={2004},
    publisher={American Economic Association},
    doi={10.1257/0002828042002561}
}

@inproceedings{wilson2024resume,
    title={Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval},
    author={Wilson, Kyra and Caliskan, Aylin},
    booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
    year={2024},
    organization={AAAI},
    note={Also published as Brookings Institution report},
    url={https://www.brookings.edu/articles/gender-race-and-intersectional-bias-in-ai-resume-screening-via-language-model-retrieval/}
}

% ============================================================================
% Fairness in Information Retrieval
% ============================================================================

@article{gao2020toward,
    title={Toward a fair marketplace: Counterfactual evaluation of the trade-off between relevance, fairness and satisfaction in recommendation systems},
    author={Gao, Ruoyuan and Shah, Chirag},
    journal={Proceedings of the 29th ACM International Conference on Information and Knowledge Management},
    pages={2145--2148},
    year={2020}
}

@inproceedings{kay2015unequal,
    title={Unequal representation and gender stereotypes in image search results for occupations},
    author={Kay, Matthew and Matuszek, Cynthia and Munson, Sean A},
    booktitle={Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
    pages={3819--3828},
    year={2015},
    organization={ACM}
}

@article{dastin2018amazon,
    title={Amazon scraps secret AI recruiting tool that showed bias against women},
    author={Dastin, Jeffrey},
    journal={Reuters},
    year={2018},
    month={October}
}

% ============================================================================
% Statistical Methods
% ============================================================================

@book{cohen1988statistical,
    title={Statistical Power Analysis for the Behavioral Sciences},
    author={Cohen, Jacob},
    year={1988},
    edition={2nd},
    publisher={Lawrence Erlbaum Associates},
    address={Hillsdale, NJ}
}

@article{shapiro1965analysis,
    title={An analysis of variance test for normality (complete samples)},
    author={Shapiro, Samuel Sanford and Wilk, Martin B},
    journal={Biometrika},
    volume={52},
    number={3/4},
    pages={591--611},
    year={1965},
    publisher={JSTOR}
}

@article{efron1987better,
    title={Better bootstrap confidence intervals},
    author={Efron, Bradley},
    journal={Journal of the American Statistical Association},
    volume={82},
    number={397},
    pages={171--185},
    year={1987},
    publisher={Taylor \& Francis}
}

% ============================================================================
% Language Models
% ============================================================================

@misc{meta2024llama,
    title={Llama 3.2: Lightweight, open models for on-device AI},
    author={{Meta AI}},
    year={2024},
    howpublished={Meta AI Blog},
    url={https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/}
}

@article{touvron2023llama,
    title={Llama 2: Open foundation and fine-tuned chat models},
    author={Touvron, Hugo and others},
    journal={arXiv preprint arXiv:2307.09288},
    year={2023}
}

@inproceedings{vaswani2017attention,
    title={Attention is all you need},
    author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
    booktitle={Advances in Neural Information Processing Systems},
    volume={30},
    year={2017}
}

% ============================================================================
% Algorithmic Fairness General
% ============================================================================

@article{barocas2016big,
    title={Big data's disparate impact},
    author={Barocas, Solon and Selbst, Andrew D},
    journal={California Law Review},
    volume={104},
    pages={671},
    year={2016}
}

@inproceedings{beutel2017data,
    title={Data decisions and theoretical implications when adversarially learning fair representations},
    author={Beutel, Alex and Chen, Jilin and Zhao, Zhe and Chi, Ed H},
    booktitle={Proceedings of the 2017 Workshop on Fairness, Accountability, and Transparency in Machine Learning},
    year={2017}
}
